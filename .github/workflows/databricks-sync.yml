name: CI/CD Pipeline - Databricks Sync

on:
  push:
    branches:
      - dev
      - main
  pull_request:
    branches:
      - dev
      - main

env:
  DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
  DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

jobs:
  test:
    name: Run Unit Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pyyaml pandas scikit-learn numpy
          
      - name: Run unit tests
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          pytest tests/ -v --tb=short
          
      - name: Test results summary
        if: always()
        run: |
          echo "Tests completed. Check output above for details."

  sync:
    name: Sync to Databricks
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push'  # Only sync on pushes, not PRs
    environment:
      name: ${{ github.ref == 'refs/heads/main' && 'databricks-prod' || 'databricks-dev' }}
      url: https://databricks.com
    env:
      DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
      DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0  # Needed for detecting deleted files
          
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install Databricks CLI
        run: |
          python -m pip install --upgrade pip
          pip install databricks-cli
          
      - name: Configure Databricks CLI
        run: |
          echo "[DEFAULT]" > ~/.databrickscfg
          echo "host = ${{ secrets.DATABRICKS_HOST }}" >> ~/.databrickscfg
          echo "token = ${{ secrets.DATABRICKS_TOKEN }}" >> ~/.databrickscfg
          chmod 600 ~/.databrickscfg
          
      - name: Configure Jobs API 2.1
        run: |
          databricks jobs configure --version=2.1 || echo "Could not configure Jobs API version, continuing..."
          
      - name: Verify Databricks credentials
        run: |
          if [ -z "${{ secrets.DATABRICKS_HOST }}" ] || [ -z "${{ secrets.DATABRICKS_TOKEN }}" ]; then
            echo "ERROR: Databricks secrets are not set!"
            echo "Please add DATABRICKS_HOST and DATABRICKS_TOKEN secrets to GitHub"
            exit 1
          fi
          echo "✓ Databricks credentials verified"
          
      - name: Determine target workspace path
        id: target_path
        run: |
          if [ "${{ github.ref }}" == "refs/heads/main" ]; then
            echo "workspace_path=/ml-regression-model-prod" >> $GITHUB_OUTPUT
          else
            echo "workspace_path=/ml-regression-model-dev" >> $GITHUB_OUTPUT
          fi
          
      - name: Upload repository files to Databricks
        run: |
          python .github/scripts/sync_to_databricks.py \
            --source-dir "." \
            --target-path "${{ steps.target_path.outputs.workspace_path }}" \
            --branch "${{ github.ref_name }}"
            
      - name: Display sync summary
        run: |
          echo "Workspace Sync Completed"
          echo "Target Path: ${{ steps.target_path.outputs.workspace_path }}"
          echo "Branch: ${{ github.ref_name }}"
          echo "Commit: ${{ github.sha }}"
          
      - name: Determine job config file
        id: job_config
        run: |
          if [ "${{ github.ref }}" == "refs/heads/main" ]; then
            echo "config_file=config/databricks_job_config_prod.json" >> $GITHUB_OUTPUT
          else
            echo "config_file=config/databricks_job_config.json" >> $GITHUB_OUTPUT
          fi
          
      - name: Check if job config changed
        id: config_changed
        run: |
          # Check if config file exists in previous commit
          if git rev-parse HEAD~1 >/dev/null 2>&1; then
            if git diff HEAD~1 HEAD --exit-code ${{ steps.job_config.outputs.config_file }} > /dev/null 2>&1; then
              echo "changed=false" >> $GITHUB_OUTPUT
              echo "Job config unchanged - skipping job update"
            else
              echo "changed=true" >> $GITHUB_OUTPUT
              echo "Job config changed - will update job"
            fi
          else
            # First commit - always update
            echo "changed=true" >> $GITHUB_OUTPUT
            echo "First commit - will create/update job"
          fi
          
      - name: Create/Update Databricks Job (Serverless)
        if: steps.config_changed.outputs.changed == 'true' || github.event_name == 'push'
        run: |
          python .github/scripts/manage_databricks_job.py \
            --config "${{ steps.job_config.outputs.config_file }}" \
            --force-update

  cleanup-deleted-files:
    name: Clean up Deleted Files from Databricks
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push'
    environment:
      name: ${{ github.ref == 'refs/heads/main' && 'databricks-prod' || 'databricks-dev' }}
      url: https://databricks.com
    env:
      DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
      DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
          
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install Databricks CLI
        run: |
          python -m pip install --upgrade pip
          pip install databricks-cli
          
      - name: Configure Databricks CLI
        run: |
          echo "[DEFAULT]" > ~/.databrickscfg
          echo "host = ${{ secrets.DATABRICKS_HOST }}" >> ~/.databrickscfg
          echo "token = ${{ secrets.DATABRICKS_TOKEN }}" >> ~/.databrickscfg
          chmod 600 ~/.databrickscfg
          
      - name: Configure Jobs API 2.1
        run: |
          databricks jobs configure --version=2.1 || echo "Could not configure Jobs API version, continuing..."
          
      - name: Verify Databricks credentials
        run: |
          if [ -z "${{ secrets.DATABRICKS_HOST }}" ] || [ -z "${{ secrets.DATABRICKS_TOKEN }}" ]; then
            echo "ERROR: Databricks secrets are not set!"
            echo "Please add DATABRICKS_HOST and DATABRICKS_TOKEN secrets to GitHub"
            exit 1
          fi
          echo "✓ Databricks credentials verified"
          
      - name: Determine target workspace path
        id: target_path
        run: |
          if [ "${{ github.ref }}" == "refs/heads/main" ]; then
            echo "workspace_path=/ml-regression-model-prod" >> $GITHUB_OUTPUT
          else
            echo "workspace_path=/ml-regression-model-dev" >> $GITHUB_OUTPUT
          fi
          
      - name: Remove deleted files from Databricks
        run: |
          python .github/scripts/cleanup_deleted_files.py \
            --target-path "${{ steps.target_path.outputs.workspace_path }}" \
            --branch "${{ github.ref_name }}"