{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "176fe5d5",
   "metadata": {},
   "source": [
    "# ML Model Inference\n",
    "\n",
    "This notebook performs inference (predictions) using the trained linear regression model.\n",
    "\n",
    "## Workflow:\n",
    "1. Load trained model\n",
    "2. Load new data for prediction\n",
    "3. Make predictions\n",
    "4. Save results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f731eff",
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.insert(0, '/Workspace/ml-regression-model-dev/src')\n",
    "\n",
    "# For development, you can use:\n",
    "# sys.path.insert(0, '/Workspace/ml-regression-model-prod/src')\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf134cf",
   "metadata": {},
   "source": [
    "## Load Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e7b87a",
   "metadata": {},
   "source": [
    "# Load configuration\n",
    "config_path = '/Workspace/ml-regression-model-dev/config/model_config.yaml'\n",
    "import yaml\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded\")\n",
    "print(f\"Model Type: {config['model']['type']}\")\n",
    "print(f\"Features: {config['model']['features']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4877b59d",
   "metadata": {},
   "source": [
    "## Load Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a345d504",
   "metadata": {},
   "source": [
    "# Path to trained model\n",
    "model_path = '/Workspace/ml-regression-model-dev/models/trained_model.pkl'\n",
    "\n",
    "# Check if model exists\n",
    "try:\n",
    "    model = joblib.load(model_path)\n",
    "    print(f\" Model loaded from {model_path}\")\n",
    "    print(f\"Model type: {type(model).__name__}\")\n",
    "    print(f\"Model coefficients: {model.coef_}\")\n",
    "    print(f\"Model intercept: {model.intercept_}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\" Model not found at {model_path}\")\n",
    "    print(\"Please run the training notebook first.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88839e90",
   "metadata": {},
   "source": [
    "## Load Inference Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7977ccbc",
   "metadata": {},
   "source": [
    "# For demo, we'll use Boston Housing test data\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Load the Boston Housing dataset\n",
    "boston = load_boston()\n",
    "X_data = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y_data = pd.Series(boston.target, name='target')\n",
    "\n",
    "# Use last 10 samples for inference\n",
    "X_inference = X_data.iloc[-10:].copy()\n",
    "y_actual = y_data.iloc[-10:].copy()\n",
    "\n",
    "print(f\" Inference data loaded\")\n",
    "print(f\"Shape: {X_inference.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(X_inference.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4828591",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2564db11",
   "metadata": {},
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_inference)\n",
    "\n",
    "print(f\" Predictions completed\")\n",
    "print(f\"Number of predictions: {len(predictions)}\")\n",
    "print(f\"\\nPredictions:\\n{predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcc1a2b",
   "metadata": {},
   "source": [
    "## Evaluate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47ca129",
   "metadata": {},
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_actual, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_actual, predictions)\n",
    "r2 = r2_score(y_actual, predictions)\n",
    "\n",
    "print(f\" Inference Metrics:\")\n",
    "print(f\"  MSE:  {mse:.4f}\")\n",
    "print(f\"  RMSE: {rmse:.4f}\")\n",
    "print(f\"  MAE:  {mae:.4f}\")\n",
    "print(f\"  R²:   {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f971cd3",
   "metadata": {},
   "source": [
    "## Save Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cd09f2",
   "metadata": {},
   "source": [
    "# Create results dataframe\n",
    "results = pd.DataFrame({\n",
    "    'actual': y_actual.values,\n",
    "    'predicted': predictions,\n",
    "    'error': np.abs(y_actual.values - predictions),\n",
    "    'relative_error': np.abs((y_actual.values - predictions) / y_actual.values * 100)\n",
    "})\n",
    "\n",
    "print(\" Results DataFrame:\")\n",
    "print(results)\n",
    "\n",
    "# Save predictions\n",
    "output_path = '/Workspace/ml-regression-model-dev/outputs/inference_results.csv'\n",
    "results.to_csv(output_path, index=False)\n",
    "print(f\"\\n Predictions saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ba6cd9",
   "metadata": {},
   "source": [
    "## Save Inference Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aba2aa",
   "metadata": {},
   "source": [
    "# Save inference metrics as JSON\n",
    "inference_metrics = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'num_samples': len(predictions),\n",
    "    'mse': float(mse),\n",
    "    'rmse': float(rmse),\n",
    "    'mae': float(mae),\n",
    "    'r2': float(r2),\n",
    "    'predictions_sample': predictions[:5].tolist()\n",
    "}\n",
    "\n",
    "metrics_path = '/Workspace/ml-regression-model-dev/outputs/inference_metrics.json'\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(inference_metrics, f, indent=2)\n",
    "\n",
    "print(f\" Inference metrics saved to {metrics_path}\")\n",
    "print(f\"\\nMetrics:\")\n",
    "print(json.dumps(inference_metrics, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a500d441",
   "metadata": {},
   "source": [
    "## Inference Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df8428a",
   "metadata": {},
   "source": [
    "print(\"=\"*60)\n",
    "print(\"INFERENCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\" Model loaded: {model_path}\")\n",
    "print(f\" Samples processed: {len(predictions)}\")\n",
    "print(f\" Predictions saved: {output_path}\")\n",
    "print(f\" Metrics saved: {metrics_path}\")\n",
    "print(f\"\\nPerformance Metrics:\")\n",
    "print(f\"  RMSE: {rmse:.4f}\")\n",
    "print(f\"  MAE:  {mae:.4f}\")\n",
    "print(f\"  R²:   {r2:.4f}\")\n",
    "print(\"=\"*60)\n",
    "print(\" Inference completed successfully!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
